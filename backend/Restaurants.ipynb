{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0971b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install googlemaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64464063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import googlemaps, time, pandas as pd\n",
    "# from datetime import datetime\n",
    "\n",
    "# API_KEY = \"AIzaSyDH9YA_5vi5bJEH7U9QCTt4wehOal8q_YE\"\n",
    "# gmaps = googlemaps.Client(key=API_KEY)\n",
    "\n",
    "# # Pune center coordinates\n",
    "# location = (18.5204, 73.8567)\n",
    "# radius = 60000  # meters (adjust; high radius may not be allowed)\n",
    "\n",
    "# places = []\n",
    "# page_token = None\n",
    "\n",
    "# while True:\n",
    "#     res = gmaps.places_nearby(location=location, radius=radius, type=\"restaurant\", page_token=page_token)\n",
    "#     for p in res.get(\"results\", []):\n",
    "#         places.append(p)\n",
    "# #         break\n",
    "#     page_token = res.get(\"next_page_token\")\n",
    "#     if not page_token:\n",
    "#         break\n",
    "#     # Google recommends waiting before using next_page_token\n",
    "#     time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7444e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61080121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Fetch details for each place (optional; costs extra)\n",
    "# rows = []\n",
    "# for p in places[:2000]:\n",
    "#     pid = p[\"place_id\"]\n",
    "#     details = gmaps.place(\n",
    "#         place_id=pid,\n",
    "#         fields=[\n",
    "#             \"name\", \"formatted_address\", \"geometry\", \"international_phone_number\", \"cuisine\", \"rating\", \"type\", \"reviews\",\n",
    "#             \"secondary_opening_hours\", \"dine_in\", \"editorial_summary\", \"price_level\", \"delivery\", \"serves_wine\",\n",
    "#             \"formatted_phone_number\", \"place_id\", \"serves_beer\", \"reservable\", \"serves_brunch\", \"serves_dinner\",\n",
    "#             \"review\", \"vicinity\", \"url\", \"serves_vegetarian_food\", \"curbside_pickup\", \"photo\", \"current_opening_hours\",\n",
    "#             \"opening_hours\", \"serves_lunch\", \"takeout\", \"user_ratings_total\", \"permanently_closed\", \"serves_breakfast\"\n",
    "#         ]\n",
    "#     )\n",
    "#     d = details.get(\"result\", {})\n",
    "#     rows.append({\n",
    "#         \"place_id\": pid,\n",
    "#         \"name\": d.get(\"name\"),\n",
    "#         \"address\": d.get(\"formatted_address\"),\n",
    "#         \"latitude\": d.get(\"geometry\", {}).get(\"location\", {}).get(\"lat\"),\n",
    "#         \"longitude\": d.get(\"geometry\", {}).get(\"location\", {}).get(\"lng\"),\n",
    "#         \"phone\": d.get(\"international_phone_number\"),\n",
    "#         \"formatted_phone_number\": d.get(\"formatted_phone_number\"),\n",
    "#         \"cuisine\": d.get(\"cuisine\"),\n",
    "#         \"rating\": d.get(\"rating\"),\n",
    "#         \"types\": \",\".join(d.get(\"type\", [])),\n",
    "#         \"reviews\": d.get(\"reviews\"),\n",
    "#         \"user_ratings_total\": d.get(\"user_ratings_total\"),\n",
    "#         \"price_level\": d.get(\"price_level\"),\n",
    "#         \"vicinity\": d.get(\"vicinity\"),\n",
    "#         \"url\": d.get(\"url\"),\n",
    "#         \"reservable\": d.get(\"reservable\"),\n",
    "#         \"delivery\": d.get(\"delivery\"),\n",
    "#         \"takeout\": d.get(\"takeout\"),\n",
    "#         \"dine_in\": d.get(\"dine_in\"),\n",
    "#         \"serves_breakfast\": d.get(\"serves_breakfast\"),\n",
    "#         \"serves_lunch\": d.get(\"serves_lunch\"),\n",
    "#         \"serves_dinner\": d.get(\"serves_dinner\"),\n",
    "#         \"serves_brunch\": d.get(\"serves_brunch\"),\n",
    "#         \"serves_beer\": d.get(\"serves_beer\"),\n",
    "#         \"serves_wine\": d.get(\"serves_wine\"),\n",
    "#         \"serves_vegetarian_food\": d.get(\"serves_vegetarian_food\"),\n",
    "#         \"curbside_pickup\": d.get(\"curbside_pickup\"),\n",
    "#         \"permanently_closed\": d.get(\"permanently_closed\"),\n",
    "#         \"editorial_summary\": d.get(\"editorial_summary\", {}).get(\"overview\"),\n",
    "#         \"opening_hours\": d.get(\"opening_hours\"),\n",
    "#         \"current_opening_hours\": d.get(\"current_opening_hours\"),\n",
    "#         \"secondary_opening_hours\": d.get(\"secondary_opening_hours\"),\n",
    "#         \"photo\": d.get(\"photo\"),\n",
    "#         \"scrape_timestamp\": datetime.utcnow().isoformat()\n",
    "#     })\n",
    "#     time.sleep(0.1)  # respect rate limits\n",
    "    \n",
    "# data =pd.DataFrame(rows)\n",
    "\n",
    "# import pandas as pd\n",
    "# pd.DataFrame(rows).to_csv(\"pune_restaurants_google5.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b11be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install googlemaps pandas python-dotenv tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422e6d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching restaurants: 100%|██████████| 7/7 [00:52<00:00,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Collected 420 records successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import googlemaps\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# ⚠️ For testing only — avoid keeping the key in public repos\n",
    "API_KEY = \"AIzaSyDH9YA_5vi5bJEH7U9QCTt4wehOal8q_YE\"\n",
    "gmaps = googlemaps.Client(key=API_KEY)\n",
    "\n",
    "def fetch_places(query, location=\"Pune, India\", radius=10000):\n",
    "    \"\"\"Fetch restaurant data from Google Places API for a specific query.\"\"\"\n",
    "    results = []\n",
    "    next_page_token = None\n",
    "    for _ in range(3):  # limit to 3 pages (~60 results per query)\n",
    "        response = gmaps.places(query=query, location=location, radius=radius)\n",
    "        results.extend(response.get('results', []))\n",
    "        next_page_token = response.get('next_page_token')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "        time.sleep(2)  # Respect rate limit\n",
    "    return results\n",
    "\n",
    "def collect_restaurants():\n",
    "    \"\"\"Collect restaurants for multiple cuisines and save to CSV.\"\"\"\n",
    "    cuisines = [\"Indian\", \"Chinese\", \"Italian\", \"South Indian\", \"North Indian\", \"Cafe\", \"Fast Food\"]\n",
    "    all_data = []\n",
    "\n",
    "    for cuisine in tqdm(cuisines, desc=\"Fetching restaurants\"):\n",
    "        data = fetch_places(f\"{cuisine} restaurants in Pune\")\n",
    "        for d in data:\n",
    "            all_data.append({\n",
    "                \"name\": d.get(\"name\"),\n",
    "                \"cuisine\": cuisine,\n",
    "                \"address\": d.get(\"formatted_address\") or d.get(\"vicinity\"),\n",
    "                \"latitude\": d.get(\"geometry\", {}).get(\"location\", {}).get(\"lat\"),\n",
    "                \"longitude\": d.get(\"geometry\", {}).get(\"location\", {}).get(\"lng\"),\n",
    "                \"phone\": d.get(\"international_phone_number\"),\n",
    "                \"formatted_phone_number\": d.get(\"formatted_phone_number\"),\n",
    "                \"rating\": d.get(\"rating\"),\n",
    "                \"types\": \",\".join(d.get(\"type\", [])),\n",
    "                \"reviews\": d.get(\"reviews\"),\n",
    "                \"user_ratings_total\": d.get(\"user_ratings_total\"),\n",
    "                \"price_level\": d.get(\"price_level\"),\n",
    "                \"vicinity\": d.get(\"vicinity\"),\n",
    "                \"url\": d.get(\"url\"),\n",
    "                \"reservable\": d.get(\"reservable\"),\n",
    "                \"delivery\": d.get(\"delivery\"),\n",
    "                \"takeout\": d.get(\"takeout\"),\n",
    "                \"dine_in\": d.get(\"dine_in\"),\n",
    "                \"serves_breakfast\": d.get(\"serves_breakfast\"),\n",
    "                \"serves_lunch\": d.get(\"serves_lunch\"),\n",
    "                \"serves_dinner\": d.get(\"serves_dinner\"),\n",
    "                \"serves_brunch\": d.get(\"serves_brunch\"),\n",
    "                \"serves_beer\": d.get(\"serves_beer\"),\n",
    "                \"serves_wine\": d.get(\"serves_wine\"),\n",
    "                \"serves_vegetarian_food\": d.get(\"serves_vegetarian_food\"),\n",
    "                \"curbside_pickup\": d.get(\"curbside_pickup\"),\n",
    "                \"permanently_closed\": d.get(\"permanently_closed\"),\n",
    "                \"editorial_summary\": d.get(\"editorial_summary\", {}).get(\"overview\"),\n",
    "                \"opening_hours\": d.get(\"opening_hours\"),\n",
    "                \"current_opening_hours\": d.get(\"current_opening_hours\"),\n",
    "                \"secondary_opening_hours\": d.get(\"secondary_opening_hours\"),\n",
    "                \"scrape_timestamp\": datetime.utcnow().isoformat()\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df.to_csv(\"pune_restaurants_raw.csv\", index=False)\n",
    "    print(f\"✅ Collected {len(df)} records successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    collect_restaurants()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9223655a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌐 Total grid points: 289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Indian:  73%|███████▎  | 211/289 [05:39<03:37,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 1500 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Indian: 100%|██████████| 289/289 [07:14<00:00,  1.50s/it]\n",
      "Fetching Chinese: 100%|██████████| 289/289 [05:10<00:00,  1.07s/it]\n",
      "Fetching Italian: 100%|██████████| 289/289 [04:22<00:00,  1.10it/s]\n",
      "Fetching South Indian: 100%|██████████| 289/289 [04:18<00:00,  1.12it/s]\n",
      "Fetching North Indian:  94%|█████████▍| 273/289 [04:43<00:13,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 3000 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching North Indian:  95%|█████████▌| 275/289 [04:45<00:12,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 3000 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching North Indian:  96%|█████████▌| 276/289 [04:46<00:12,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 3000 rows so far\n",
      "💾 Checkpoint saved → 3000 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching North Indian:  96%|█████████▌| 277/289 [04:47<00:11,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 3000 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching North Indian:  97%|█████████▋| 279/289 [04:49<00:08,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 3000 rows so far\n",
      "💾 Checkpoint saved → 3000 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching North Indian:  97%|█████████▋| 280/289 [04:50<00:07,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 3000 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching North Indian:  97%|█████████▋| 281/289 [04:51<00:07,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 3000 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching North Indian:  98%|█████████▊| 282/289 [04:52<00:07,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 3000 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching North Indian:  98%|█████████▊| 283/289 [04:53<00:06,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 3000 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching North Indian:  99%|█████████▊| 285/289 [04:55<00:03,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 3000 rows so far\n",
      "💾 Checkpoint saved → 3000 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching North Indian:  99%|█████████▉| 287/289 [04:57<00:01,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 3000 rows so far\n",
      "💾 Checkpoint saved → 3000 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching North Indian: 100%|██████████| 289/289 [04:59<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 3000 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching North Indian: 100%|██████████| 289/289 [04:59<00:00,  1.04s/it]\n",
      "Fetching Cafe: 100%|██████████| 289/289 [05:51<00:00,  1.22s/it]\n",
      "Fetching Fast Food: 100%|██████████| 289/289 [08:04<00:00,  1.68s/it]\n",
      "Fetching Seafood:  87%|████████▋ | 250/289 [03:48<00:36,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 5700 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Seafood:  87%|████████▋ | 251/289 [03:49<00:36,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 5700 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Seafood:  88%|████████▊ | 253/289 [03:51<00:35,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 5700 rows so far\n",
      "💾 Checkpoint saved → 5700 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Seafood:  88%|████████▊ | 254/289 [03:52<00:33,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 5700 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Seafood:  89%|████████▊ | 256/289 [03:54<00:32,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 5700 rows so far\n",
      "💾 Checkpoint saved → 5700 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Seafood:  89%|████████▉ | 257/289 [03:55<00:31,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 5700 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Seafood:  89%|████████▉ | 258/289 [03:56<00:30,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 5700 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Seafood:  90%|████████▉ | 259/289 [03:57<00:28,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 5700 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Seafood:  90%|████████▉ | 260/289 [03:58<00:28,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 5700 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Seafood:  90%|█████████ | 261/289 [03:59<00:27,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 5700 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Seafood:  91%|█████████ | 262/289 [04:00<00:26,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 5700 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Seafood: 100%|██████████| 289/289 [04:24<00:00,  1.09it/s]\n",
      "Fetching Mughlai: 100%|██████████| 289/289 [04:46<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Final dataset saved → data/raw/pune_restaurants_full.csv (5925 rows)\n",
      "✅ Completed: 5925 unique restaurants collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Google Places Data Collector for Pune Restaurants\n",
    "-------------------------------------------------\n",
    "Features:\n",
    " - Grid-based sweep across Pune\n",
    " - Multi-cuisine coverage\n",
    " - Auto cuisine extraction from `types`\n",
    " - Duplicate removal using place_id\n",
    " - Safe progress checkpointing (CSV)\n",
    "\"\"\"\n",
    "\n",
    "import googlemaps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 🔑 API SETUP\n",
    "# ────────────────────────────────────────────────\n",
    "API_KEY = \"AIzaSyDH9YA_5vi5bJEH7U9QCTt4wehOal8q_YE\"\n",
    "gmaps = googlemaps.Client(key=API_KEY)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# ⚙️ PARAMETERS\n",
    "# ────────────────────────────────────────────────\n",
    "CENTER_LAT, CENTER_LNG = 18.5204, 73.8567  # Pune center\n",
    "GRID_RADIUS_KM = 25\n",
    "STEP_KM = 3  # distance between grid centers\n",
    "SEARCH_RADIUS = 2000  # meters per query circle\n",
    "CUISINES = [\"Indian\", \"Chinese\", \"Italian\", \"South Indian\",\n",
    "            \"North Indian\", \"Cafe\", \"Fast Food\", \"Seafood\", \"Mughlai\"]\n",
    "\n",
    "OUTPUT_FILE = \"data/raw/pune_restaurants_full.csv\"\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 🗺️ GRID CREATION\n",
    "# ────────────────────────────────────────────────\n",
    "def make_grid(center_lat, center_lng, km_radius=25, step_km=3):\n",
    "    \"\"\"Create grid of lat/lng points covering Pune.\"\"\"\n",
    "    dlat = step_km / 110.574\n",
    "    dlng = step_km / (111.320 * np.cos(np.radians(center_lat)))\n",
    "    lat_points = np.arange(center_lat - km_radius/110.574,\n",
    "                           center_lat + km_radius/110.574, dlat)\n",
    "    lng_points = np.arange(center_lng - km_radius/(111.320*np.cos(np.radians(center_lat))),\n",
    "                           center_lng + km_radius/(111.320*np.cos(np.radians(center_lat))), dlng)\n",
    "    return [(lat, lng) for lat in lat_points for lng in lng_points]\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 🔍 FETCH FUNCTION\n",
    "# ────────────────────────────────────────────────\n",
    "def fetch_places(lat, lng, keyword):\n",
    "    \"\"\"Fetch all pages of results for one area and keyword.\"\"\"\n",
    "    results = []\n",
    "    next_token = None\n",
    "    for _ in range(3):\n",
    "        res = gmaps.places_nearby(\n",
    "            location=(lat, lng),\n",
    "            radius=SEARCH_RADIUS,\n",
    "            keyword=f\"{keyword} restaurant\",\n",
    "            type=\"restaurant\",\n",
    "            page_token=next_token\n",
    "        )\n",
    "        results += res.get(\"results\", [])\n",
    "        next_token = res.get(\"next_page_token\")\n",
    "        if not next_token:\n",
    "            break\n",
    "        time.sleep(2)  # required by Google\n",
    "    return results\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 🍴 MAIN COLLECTION LOOP\n",
    "# ────────────────────────────────────────────────\n",
    "def collect_restaurants():\n",
    "    grid_points = make_grid(CENTER_LAT, CENTER_LNG, GRID_RADIUS_KM, STEP_KM)\n",
    "    all_places = {}\n",
    "    print(f\"🌐 Total grid points: {len(grid_points)}\")\n",
    "\n",
    "    for cuisine in CUISINES:\n",
    "        for lat, lng in tqdm(grid_points, desc=f\"Fetching {cuisine}\"):\n",
    "            try:\n",
    "                results = fetch_places(lat, lng, cuisine)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error at {lat},{lng}: {e}\")\n",
    "                continue\n",
    "\n",
    "            for r in results:\n",
    "                pid = r.get(\"place_id\")\n",
    "                if not pid:\n",
    "                    continue\n",
    "\n",
    "                # Skip duplicates\n",
    "                if pid not in all_places:\n",
    "                    all_places[pid] = {\n",
    "                        \"place_id\": pid,\n",
    "                        \"name\": r.get(\"name\"),\n",
    "                        \"address\": r.get(\"vicinity\") or r.get(\"formatted_address\"),\n",
    "                        \"rating\": r.get(\"rating\"),\n",
    "                        \"user_ratings_total\": r.get(\"user_ratings_total\"),\n",
    "                        \"latitude\": r.get(\"geometry\", {}).get(\"location\", {}).get(\"lat\"),\n",
    "                        \"longitude\": r.get(\"geometry\", {}).get(\"location\", {}).get(\"lng\"),\n",
    "                        \"price_level\": r.get(\"price_level\"),\n",
    "                        \"url\": r.get(\"url\"),\n",
    "                        \"types\": r.get(\"types\", []),\n",
    "                        \"cuisines\": set()\n",
    "                    }\n",
    "\n",
    "                # Merge cuisine + extract from types\n",
    "                entry = all_places[pid]\n",
    "                entry[\"cuisines\"].add(cuisine)\n",
    "                for t in r.get(\"types\", []):\n",
    "                    if \"restaurant\" in t and t != \"restaurant\":\n",
    "                        entry[\"cuisines\"].add(t.replace(\"_restaurant\", \"\").replace(\"_\", \" \").title())\n",
    "\n",
    "            # Save checkpoint every 15 grid points\n",
    "            if len(all_places) % 300 == 0:\n",
    "                save_checkpoint(all_places)\n",
    "\n",
    "            time.sleep(0.2)\n",
    "\n",
    "    # Final save\n",
    "    save_checkpoint(all_places, final=True)\n",
    "    print(f\"✅ Completed: {len(all_places)} unique restaurants collected.\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 💾 SAVE FUNCTION\n",
    "# ────────────────────────────────────────────────\n",
    "def save_checkpoint(all_places, final=False):\n",
    "    df = pd.DataFrame([\n",
    "        {\n",
    "            \"place_id\": v[\"place_id\"],\n",
    "            \"name\": v[\"name\"],\n",
    "            \"address\": v[\"address\"],\n",
    "            \"latitude\": v[\"latitude\"],\n",
    "            \"longitude\": v[\"longitude\"],\n",
    "            \"rating\": v[\"rating\"],\n",
    "            \"user_ratings_total\": v[\"user_ratings_total\"],\n",
    "            \"price_level\": v[\"price_level\"],\n",
    "            \"cuisine\": \", \".join(sorted(v[\"cuisines\"])),\n",
    "            \"types\": \", \".join(v[\"types\"]),\n",
    "            \"url\": v[\"url\"],\n",
    "            \"scrape_timestamp\": datetime.utcnow().isoformat()\n",
    "        }\n",
    "        for v in all_places.values()\n",
    "    ])\n",
    "    df.to_csv(OUTPUT_FILE, index=False)\n",
    "    if final:\n",
    "        print(f\"💾 Final dataset saved → {OUTPUT_FILE} ({len(df)} rows)\")\n",
    "    else:\n",
    "        print(f\"💾 Checkpoint saved → {len(df)} rows so far\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 🚀 EXECUTION\n",
    "# ────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    collect_restaurants()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7e549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌐 Total grid points: 289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Indian:  95%|█████████▍| 274/289 [18:14<00:59,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛑 Limit of 2000 reached. Stopping.\n",
      "💾 Final dataset saved → data/raw/pune_restaurants_with_phone.csv (2011 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Google Places Data Collector for Pune (with Phone Numbers)\n",
    "----------------------------------------------------------\n",
    "Features:\n",
    " - Grid-based sweep across Pune\n",
    " - Multi-cuisine coverage\n",
    " - Fetches phone numbers using Place Details API\n",
    " - Stops at ~2000 restaurants\n",
    " - Duplicate handling via place_id\n",
    "\"\"\"\n",
    "\n",
    "import googlemaps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# ============ 🔑 API SETUP ============\n",
    "API_KEY = \"AIzaSyDH9YA_5vi5bJEH7U9QCTt4wehOal8q_YE\"\n",
    "gmaps = googlemaps.Client(key=API_KEY)\n",
    "\n",
    "# ============ ⚙️ PARAMETERS ============\n",
    "CENTER_LAT, CENTER_LNG = 18.5204, 73.8567  # Pune center\n",
    "GRID_RADIUS_KM = 25\n",
    "STEP_KM = 3\n",
    "SEARCH_RADIUS = 2000\n",
    "# CUISINES = [\"Indian\", \"Chinese\", \"Italian\", \"South Indian\",\n",
    "#             \"North Indian\", \"Cafe\", \"Fast Food\", \"Seafood\", \"Mughlai\"]\n",
    "CUISINES = [\"Indian\", \"Chinese\", \"Italian\", \"South Indian\", \"North Indian\",\n",
    "            \"Cafe\", \"Fast Food\", \"Seafood\", \"Mughlai\", \"Vegan\", \"Street Food\",\n",
    "            \"Dessert\", \"Bakery\", \"Goan\", \"Punjabi\", \"Thai\", \"Mexican\", \"Burger\",\n",
    "            \"Japanese\", \"Mediterranean\"]\n",
    "\n",
    "OUTPUT_FILE = \"data/raw/pune_restaurants_with_phone.csv\"\n",
    "MAX_RESTAURANTS = 2000\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "\n",
    "\n",
    "# ============ 🗺️ GRID CREATION ============\n",
    "def make_grid(center_lat, center_lng, km_radius=25, step_km=3):\n",
    "    \"\"\"Create lat/lng grid points across Pune.\"\"\"\n",
    "    dlat = step_km / 110.574\n",
    "    dlng = step_km / (111.320 * np.cos(np.radians(center_lat)))\n",
    "    lat_points = np.arange(center_lat - km_radius / 110.574,\n",
    "                           center_lat + km_radius / 110.574, dlat)\n",
    "    lng_points = np.arange(center_lng - km_radius / (111.320 * np.cos(np.radians(center_lat))),\n",
    "                           center_lng + km_radius / (111.320 * np.cos(np.radians(center_lat))), dlng)\n",
    "    return [(lat, lng) for lat in lat_points for lng in lng_points]\n",
    "\n",
    "\n",
    "# ============ 🔍 FETCH PLACES ============\n",
    "def fetch_places(lat, lng, keyword):\n",
    "    \"\"\"Fetch nearby restaurants for one area and keyword.\"\"\"\n",
    "    results = []\n",
    "    next_token = None\n",
    "    for _ in range(3):\n",
    "        res = gmaps.places_nearby(\n",
    "            location=(lat, lng),\n",
    "            radius=SEARCH_RADIUS,\n",
    "            keyword=f\"{keyword} restaurant\",\n",
    "            type=\"restaurant\",\n",
    "            page_token=next_token\n",
    "        )\n",
    "        results += res.get(\"results\", [])\n",
    "        next_token = res.get(\"next_page_token\")\n",
    "        if not next_token:\n",
    "            break\n",
    "        time.sleep(2)  # required by Google\n",
    "    return results\n",
    "\n",
    "\n",
    "# ============ ☎️ FETCH PHONE DETAILS ============\n",
    "def fetch_phone_details(place_id):\n",
    "    \"\"\"Fetch phone number via Place Details API.\"\"\"\n",
    "    try:\n",
    "        details = gmaps.place(\n",
    "            place_id=place_id,\n",
    "            fields=[\"formatted_phone_number\", \"international_phone_number\", \"website\"]\n",
    "        )\n",
    "        result = details.get(\"result\", {})\n",
    "        phone = result.get(\"international_phone_number\") or result.get(\"formatted_phone_number\")\n",
    "        website = result.get(\"website\")\n",
    "        return phone, website\n",
    "    except Exception as e:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# ============ 🍴 MAIN COLLECTION ============\n",
    "def collect_restaurants():\n",
    "    grid_points = make_grid(CENTER_LAT, CENTER_LNG, GRID_RADIUS_KM, STEP_KM)\n",
    "    all_places = {}\n",
    "    print(f\"🌐 Total grid points: {len(grid_points)}\")\n",
    "\n",
    "    for cuisine in CUISINES:\n",
    "        for lat, lng in tqdm(grid_points, desc=f\"Fetching {cuisine}\"):\n",
    "            try:\n",
    "                results = fetch_places(lat, lng, cuisine)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error at {lat},{lng}: {e}\")\n",
    "                continue\n",
    "\n",
    "            for r in results:\n",
    "                pid = r.get(\"place_id\")\n",
    "                if not pid:\n",
    "                    continue\n",
    "\n",
    "                if pid not in all_places:\n",
    "                    # Fetch phone once per place_id\n",
    "                    phone, website = fetch_phone_details(pid)\n",
    "                    time.sleep(0.1)\n",
    "\n",
    "                    all_places[pid] = {\n",
    "                        \"place_id\": pid,\n",
    "                        \"name\": r.get(\"name\"),\n",
    "                        \"address\": r.get(\"vicinity\") or r.get(\"formatted_address\"),\n",
    "                        \"latitude\": r.get(\"geometry\", {}).get(\"location\", {}).get(\"lat\"),\n",
    "                        \"longitude\": r.get(\"geometry\", {}).get(\"location\", {}).get(\"lng\"),\n",
    "                        \"rating\": r.get(\"rating\"),\n",
    "                        \"user_ratings_total\": r.get(\"user_ratings_total\"),\n",
    "                        \"price_level\": r.get(\"price_level\"),\n",
    "                        \"cuisines\": {cuisine},\n",
    "                        \"types\": r.get(\"types\", []),\n",
    "                        \"phone\": phone,\n",
    "                        \"website\": website,\n",
    "                        \"url\": r.get(\"url\"),\n",
    "                        \"scrape_timestamp\": datetime.utcnow().isoformat(),\n",
    "                    }\n",
    "\n",
    "                # Merge cuisines if same restaurant found again\n",
    "                else:\n",
    "                    all_places[pid][\"cuisines\"].add(cuisine)\n",
    "\n",
    "            # Save checkpoint periodically\n",
    "            if len(all_places) % 300 == 0:\n",
    "                save_checkpoint(all_places)\n",
    "\n",
    "            # Stop early if limit reached\n",
    "            if len(all_places) >= MAX_RESTAURANTS:\n",
    "                print(f\"🛑 Limit of {MAX_RESTAURANTS} reached. Stopping.\")\n",
    "                save_checkpoint(all_places, final=True)\n",
    "                return\n",
    "\n",
    "            time.sleep(0.2)\n",
    "\n",
    "    # Final save\n",
    "    save_checkpoint(all_places, final=True)\n",
    "    print(f\"✅ Completed: {len(all_places)} unique restaurants collected.\")\n",
    "\n",
    "\n",
    "# ============ 💾 SAVE CHECKPOINT ============\n",
    "def save_checkpoint(all_places, final=False):\n",
    "    df = pd.DataFrame([\n",
    "        {\n",
    "            \"place_id\": v[\"place_id\"],\n",
    "            \"name\": v[\"name\"],\n",
    "            \"address\": v[\"address\"],\n",
    "            \"latitude\": v[\"latitude\"],\n",
    "            \"longitude\": v[\"longitude\"],\n",
    "            \"rating\": v[\"rating\"],\n",
    "            \"user_ratings_total\": v[\"user_ratings_total\"],\n",
    "            \"price_level\": v[\"price_level\"],\n",
    "            \"cuisine\": \", \".join(sorted(v[\"cuisines\"])),\n",
    "            \"types\": \", \".join(v[\"types\"]),\n",
    "            \"phone\": v.get(\"phone\"),\n",
    "            \"website\": v.get(\"website\"),\n",
    "            \"url\": v.get(\"url\"),\n",
    "            \"scrape_timestamp\": v[\"scrape_timestamp\"],\n",
    "        }\n",
    "        for v in all_places.values()\n",
    "    ])\n",
    "\n",
    "    df.to_csv(OUTPUT_FILE, index=False)\n",
    "    if final:\n",
    "        print(f\"💾 Final dataset saved → {OUTPUT_FILE} ({len(df)} rows)\")\n",
    "    else:\n",
    "        print(f\"💾 Checkpoint saved → {len(df)} rows so far\")\n",
    "\n",
    "\n",
    "# ============ 🚀 RUN SCRIPT ============\n",
    "if __name__ == \"__main__\":\n",
    "    collect_restaurants()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d35f73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌐 Total grid points: 169\n",
      "\n",
      "🍽️ Collecting cuisine: Indian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indian scan: 100%|██████████| 169/169 [04:42<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Indian: 333 restaurants collected.\n",
      "\n",
      "🍽️ Collecting cuisine: Chinese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chinese scan:  73%|███████▎  | 124/169 [02:55<00:33,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 600 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chinese scan: 100%|██████████| 169/169 [03:32<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chinese: 287 restaurants collected.\n",
      "\n",
      "🍽️ Collecting cuisine: Italian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Italian scan: 100%|██████████| 169/169 [02:51<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Italian: 183 restaurants collected.\n",
      "\n",
      "🍽️ Collecting cuisine: South Indian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "South Indian scan: 100%|██████████| 169/169 [02:45<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ South Indian: 177 restaurants collected.\n",
      "\n",
      "🍽️ Collecting cuisine: North Indian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "North Indian scan: 100%|██████████| 169/169 [03:20<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ North Indian: 254 restaurants collected.\n",
      "\n",
      "🍽️ Collecting cuisine: Cafe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cafe scan: 100%|██████████| 169/169 [04:07<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cafe: 306 restaurants collected.\n",
      "\n",
      "🍽️ Collecting cuisine: Fast Food\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast Food scan:  37%|███▋      | 63/169 [02:30<01:43,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Checkpoint saved → 1800 rows so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast Food scan: 100%|██████████| 169/169 [05:02<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fast Food: 326 restaurants collected.\n",
      "\n",
      "🍽️ Collecting cuisine: Seafood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seafood scan: 100%|██████████| 169/169 [02:41<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Seafood: 133 restaurants collected.\n",
      "\n",
      "🍽️ Collecting cuisine: Mughlai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mughlai scan:   0%|          | 0/169 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛑 Limit of 2000 restaurants reached. Stopping early.\n",
      "💾 Final dataset saved → data/raw/pune_restaurants_balanced_phone.csv (2002 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Google Places Data Collector for Pune (Balanced & with Phone Numbers)\n",
    "---------------------------------------------------------------------\n",
    "Features:\n",
    " - Balanced sampling across multiple cuisines\n",
    " - Fetches phone numbers via Place Details API\n",
    " - Stops at ~2,000 total restaurants\n",
    " - Duplicate handling using place_id\n",
    " - Safe progress checkpointing (CSV)\n",
    "\"\"\"\n",
    "\n",
    "import googlemaps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 🔑 API SETUP\n",
    "# ────────────────────────────────────────────────\n",
    "API_KEY = \"AIzaSyDH9YA_5vi5bJEH7U9QCTt4wehOal8q_YE\"\n",
    "gmaps = googlemaps.Client(key=API_KEY)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# ⚙️ PARAMETERS\n",
    "# ────────────────────────────────────────────────\n",
    "CENTER_LAT, CENTER_LNG = 18.5204, 73.8567  # Pune center\n",
    "GRID_RADIUS_KM = 25\n",
    "STEP_KM = 4              # slightly larger grid spacing for uniqueness\n",
    "SEARCH_RADIUS = 1500     # 1.5 km radius to reduce overlap\n",
    "CUISINES = [\n",
    "    \"Indian\", \"Chinese\", \"Italian\", \"South Indian\",\n",
    "    \"North Indian\", \"Cafe\", \"Fast Food\", \"Seafood\", \"Mughlai\"\n",
    "]\n",
    "\n",
    "MAX_TOTAL = 2000\n",
    "MAX_PER_CUISINE = MAX_TOTAL // len(CUISINES) + 20   # ≈220 each\n",
    "OUTPUT_FILE = \"data/raw/pune_restaurants_balanced_phone.csv\"\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 🗺️ GRID CREATION\n",
    "# ────────────────────────────────────────────────\n",
    "def make_grid(center_lat, center_lng, km_radius=25, step_km=4):\n",
    "    \"\"\"Create lat/lng grid points covering Pune.\"\"\"\n",
    "    dlat = step_km / 110.574\n",
    "    dlng = step_km / (111.320 * np.cos(np.radians(center_lat)))\n",
    "    lat_points = np.arange(center_lat - km_radius / 110.574,\n",
    "                           center_lat + km_radius / 110.574, dlat)\n",
    "    lng_points = np.arange(center_lng - km_radius / (111.320 * np.cos(np.radians(center_lat))),\n",
    "                           center_lng + km_radius / (111.320 * np.cos(np.radians(center_lat))), dlng)\n",
    "    grid = [(lat, lng) for lat in lat_points for lng in lng_points]\n",
    "    random.shuffle(grid)\n",
    "    return grid\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 🔍 FETCH PLACES\n",
    "# ────────────────────────────────────────────────\n",
    "def fetch_places(lat, lng, keyword):\n",
    "    \"\"\"Fetch nearby restaurants for one grid cell and cuisine.\"\"\"\n",
    "    results = []\n",
    "    next_token = None\n",
    "    for _ in range(3):\n",
    "        res = gmaps.places_nearby(\n",
    "            location=(lat, lng),\n",
    "            radius=SEARCH_RADIUS,\n",
    "            keyword=f\"{keyword} restaurant\",\n",
    "            type=\"restaurant\",\n",
    "            page_token=next_token\n",
    "        )\n",
    "        results += res.get(\"results\", [])\n",
    "        next_token = res.get(\"next_page_token\")\n",
    "        if not next_token:\n",
    "            break\n",
    "        time.sleep(2)  # required by Google\n",
    "    return results\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# ☎️ FETCH PHONE DETAILS\n",
    "# ────────────────────────────────────────────────\n",
    "def fetch_phone_details(place_id):\n",
    "    \"\"\"Fetch phone number via Place Details API.\"\"\"\n",
    "    try:\n",
    "        details = gmaps.place(\n",
    "            place_id=place_id,\n",
    "            fields=[\"formatted_phone_number\", \"international_phone_number\", \"website\"]\n",
    "        )\n",
    "        result = details.get(\"result\", {})\n",
    "        phone = result.get(\"international_phone_number\") or result.get(\"formatted_phone_number\")\n",
    "        website = result.get(\"website\")\n",
    "        return phone, website\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 💾 SAVE CHECKPOINT\n",
    "# ────────────────────────────────────────────────\n",
    "def save_checkpoint(all_places, final=False):\n",
    "    df = pd.DataFrame([\n",
    "        {\n",
    "            \"place_id\": v[\"place_id\"],\n",
    "            \"name\": v[\"name\"],\n",
    "            \"address\": v[\"address\"],\n",
    "            \"latitude\": v[\"latitude\"],\n",
    "            \"longitude\": v[\"longitude\"],\n",
    "            \"rating\": v[\"rating\"],\n",
    "            \"user_ratings_total\": v[\"user_ratings_total\"],\n",
    "            \"price_level\": v[\"price_level\"],\n",
    "            \"cuisine\": \", \".join(sorted(v[\"cuisines\"])),\n",
    "            \"types\": \", \".join(v[\"types\"]),\n",
    "            \"phone\": v.get(\"phone\"),\n",
    "            \"website\": v.get(\"website\"),\n",
    "            \"url\": v.get(\"url\"),\n",
    "            \"scrape_timestamp\": v[\"scrape_timestamp\"]\n",
    "        }\n",
    "        for v in all_places.values()\n",
    "    ])\n",
    "    df.to_csv(OUTPUT_FILE, index=False)\n",
    "    if final:\n",
    "        print(f\"💾 Final dataset saved → {OUTPUT_FILE} ({len(df)} rows)\")\n",
    "    else:\n",
    "        print(f\"💾 Checkpoint saved → {len(df)} rows so far\")\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 🍴 MAIN COLLECTION LOOP\n",
    "# ────────────────────────────────────────────────\n",
    "def collect_restaurants():\n",
    "    grid_points = make_grid(CENTER_LAT, CENTER_LNG, GRID_RADIUS_KM, STEP_KM)\n",
    "    all_places = {}\n",
    "    cuisine_counts = {c: 0 for c in CUISINES}\n",
    "\n",
    "    print(f\"🌐 Total grid points: {len(grid_points)}\")\n",
    "\n",
    "    for cuisine in CUISINES:\n",
    "        print(f\"\\n🍽️ Collecting cuisine: {cuisine}\")\n",
    "        for lat, lng in tqdm(grid_points, desc=f\"{cuisine} scan\"):\n",
    "            try:\n",
    "                results = fetch_places(lat, lng, cuisine)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error at {lat},{lng}: {e}\")\n",
    "                continue\n",
    "\n",
    "            for r in results:\n",
    "                pid = r.get(\"place_id\")\n",
    "                if not pid or pid in all_places:\n",
    "                    continue\n",
    "\n",
    "                phone, website = fetch_phone_details(pid)\n",
    "                time.sleep(0.1)  # prevent rate-limit errors\n",
    "\n",
    "                all_places[pid] = {\n",
    "                    \"place_id\": pid,\n",
    "                    \"name\": r.get(\"name\"),\n",
    "                    \"address\": r.get(\"vicinity\") or r.get(\"formatted_address\"),\n",
    "                    \"latitude\": r.get(\"geometry\", {}).get(\"location\", {}).get(\"lat\"),\n",
    "                    \"longitude\": r.get(\"geometry\", {}).get(\"location\", {}).get(\"lng\"),\n",
    "                    \"rating\": r.get(\"rating\"),\n",
    "                    \"user_ratings_total\": r.get(\"user_ratings_total\"),\n",
    "                    \"price_level\": r.get(\"price_level\"),\n",
    "                    \"types\": r.get(\"types\", []),\n",
    "                    \"cuisines\": {cuisine},\n",
    "                    \"phone\": phone,\n",
    "                    \"website\": website,\n",
    "                    \"url\": r.get(\"url\"),\n",
    "                    \"scrape_timestamp\": datetime.utcnow().isoformat()\n",
    "                }\n",
    "\n",
    "                cuisine_counts[cuisine] += 1\n",
    "                # stop per cuisine\n",
    "                if cuisine_counts[cuisine] >= MAX_PER_CUISINE:\n",
    "                    break\n",
    "\n",
    "            # checkpoint every ~200 total\n",
    "            if len(all_places) % 200 == 0:\n",
    "                save_checkpoint(all_places)\n",
    "\n",
    "            # stop if reached total limit\n",
    "            if len(all_places) >= MAX_TOTAL:\n",
    "                print(f\"🛑 Limit of {MAX_TOTAL} restaurants reached. Stopping early.\")\n",
    "                save_checkpoint(all_places, final=True)\n",
    "                return\n",
    "\n",
    "        print(f\"✅ {cuisine}: {cuisine_counts[cuisine]} restaurants collected.\")\n",
    "\n",
    "    save_checkpoint(all_places, final=True)\n",
    "    print(f\"🎉 Completed: {len(all_places)} unique restaurants collected across all cuisines.\")\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 🚀 RUN SCRIPT\n",
    "# ────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    collect_restaurants()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
